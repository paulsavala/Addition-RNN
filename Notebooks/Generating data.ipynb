{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating data\n",
    "\n",
    "The purpose of this notebook is to generate and save some common datasets for training/testing. This way, results can easily be compared across different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "import random\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_dir = Path('../Code')\n",
    "data_dir = code_dir / Path('data')\n",
    "random_dir = data_dir / Path('random')\n",
    "sum_strat_dir = data_dir / Path('sum_strat')\n",
    "uniform_sum_dir = data_dir / Path('uniform_sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation functions\n",
    "\n",
    "Functions copy-pasted from my code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(n, max_value):\n",
    "    # One-hots a positive integer n where n <= max_value\n",
    "    one_hot_n = np.zeros(max_value)\n",
    "    one_hot_n[n] = 1\n",
    "    return one_hot_n\n",
    "\n",
    "\n",
    "def undo_one_hot(v):\n",
    "    # If an integer is one-hot encoded using the one_hot function above, return the integer n\n",
    "    return np.argmax(v)\n",
    "\n",
    "\n",
    "def one_hot_matrix(M, max_value):\n",
    "    # Given a matrix M of size (n_samples, n_ints) return the matrix one-hotted. The return matrix is\n",
    "    # of size (n_samples, n_ints, max_value)\n",
    "    n_samples, seq_length = M.shape\n",
    "    M_oh = np.array([one_hot(r, max_value) for r in np.array(M).flatten()]).reshape(\n",
    "        (n_samples, seq_length, max_value))\n",
    "\n",
    "    # In case this is a target vector, we don't want to include an unnecessary axis\n",
    "    return np.squeeze(M_oh)\n",
    "\n",
    "\n",
    "def undo_one_hot_matrix(M, decoder_map):\n",
    "    # Given a matrix M of size (n_samples, timesteps, vocab_size) coming from one_hot_matrix, return the sequence\n",
    "    # that was encoded.\n",
    "    decoded_list = []\n",
    "    for i in range(M.shape[0]):\n",
    "        decoded = ''\n",
    "        sample = M[i]\n",
    "        for ts in range(sample.shape[0]):\n",
    "            decoded += decoder_map[undo_one_hot(sample[ts])]\n",
    "        decoded_list.append(decoded)\n",
    "    return decoded_list\n",
    "\n",
    "\n",
    "def char_to_int_map(max_value=9, min_value=0):\n",
    "    char_to_int = {str(n): n for n in range(min_value, max_value+1)}\n",
    "    n_terms = max_value - min_value + 1\n",
    "    char_to_int['+'] = n_terms\n",
    "    char_to_int['\\t'] = n_terms + 1\n",
    "    char_to_int['\\n'] = n_terms + 2\n",
    "    char_to_int[' '] = n_terms + 3\n",
    "    return char_to_int\n",
    "\n",
    "\n",
    "def input_seq_length(n_terms, n_digits):\n",
    "    # Given an addition sequence with n_terms terms each with n_digits, return how many characters the (non-padded)\n",
    "    # resulting input string can be (maximum possible length)\n",
    "    # n_digits for each term, and n_terms - 1 \"plus signs\", along with an end-of-string character \\n and a\n",
    "    # start-of-string character \\t\n",
    "    return n_terms * n_digits + (n_terms - 1) + 1\n",
    "\n",
    "\n",
    "def target_seq_length(n_terms, n_digits):\n",
    "    # Given an addition sequence with n_terms terms each with n_digits, return how many characters the (non-padded)\n",
    "    # resulting output string can be (maximum possible length)\n",
    "    # All terms except the final +2 come from simple algebra computing the max number of digits possible.\n",
    "    # The final +1 comes from the start-of-sequence character \\t that is prepended to all target sequences.\n",
    "    # The inital +1 comes from the \\n appended\n",
    "    return 1 + n_digits + 1 + int(np.floor(np.log10(n_terms))) + 1\n",
    "\n",
    "\n",
    "def reverse_dict(d):\n",
    "    return {v: k for k, v in d.items()}\n",
    "\n",
    "\n",
    "int_to_char = reverse_dict(char_to_int_map())\n",
    "\n",
    "\n",
    "def decode_sample(x, decoder_map, one_hot=False):\n",
    "    # Given an array with integer encoding (or optionally one-hot encoding), decode it into\n",
    "    # a string\n",
    "    if one_hot:\n",
    "        x = undo_one_hot(x)\n",
    "    return ''.join([decoder_map[s] for s in x])\n",
    "\n",
    "\n",
    "def decode_matrix(X, decoder_map, one_hot=False):\n",
    "    # Given a matrix with integer encoding (or optionally one-hot encoding), decode it into\n",
    "    # a list of strings\n",
    "    if one_hot:\n",
    "        X = undo_one_hot_matrix(X)\n",
    "    decoded_strs = [decode_sample(x, decoder_map) for x in X] \n",
    "    return decoded_strs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_sample(n_terms, n_digits, allow_less_terms=False):\n",
    "    # Generate a sample of the form \"number_1+number_2+...+number_{n_terms}=answer\"\n",
    "    x = []\n",
    "    if allow_less_terms:\n",
    "        for _ in range(np.random.randint(2, n_terms + 1)):\n",
    "            x.append(np.random.randint(10 ** n_digits - 1))\n",
    "    else:\n",
    "        for _ in range(n_terms):\n",
    "            x.append(np.random.randint(10 ** n_digits - 1))\n",
    "\n",
    "    y = np.sum(x)\n",
    "\n",
    "    x_str = '+'.join(str(n) for n in x)\n",
    "    y_str = str(y)\n",
    "    return x_str.strip(), y_str.strip()\n",
    "\n",
    "\n",
    "def _generate_sample_from_y(n_terms, n_digits, y):\n",
    "    # Generates a sample which sums to y (used to uniformly distribute the sums)\n",
    "    x = []\n",
    "    while len(x) < n_terms - 1:\n",
    "        # Don't allow it to pick a number causing sum(x) to exceed y, but also subject\n",
    "        # to the restriction of n_digits.\n",
    "\n",
    "        # Also, don't allow it to pick such a small number that it would be impossible\n",
    "        # for the remaining terms to be chosen to sum to y (for example, if y = 150 and\n",
    "        # n_terms = 2, n_digits = 2, we can't pick 49, or else you would need 101 to sum\n",
    "        # to y.\n",
    "        y_upper_bound = y - np.sum(x)\n",
    "        n_digits_upper_bound = 10 ** n_digits - 1\n",
    "        upper_bound = min([y_upper_bound, n_digits_upper_bound])\n",
    "        lower_bound = (y - np.sum(x) - (10 ** n_digits - 1) * (n_terms - len(x) - 1))\n",
    "        lower_bound = max([0, lower_bound])\n",
    "\n",
    "        if upper_bound > 0:\n",
    "            x.append(np.random.randint(lower_bound, upper_bound + 1))\n",
    "        else:\n",
    "            x.append(0)\n",
    "    x.append(y - np.sum(x))\n",
    "    random.shuffle(x)\n",
    "\n",
    "    x_str = '+'.join(str(n) for n in x)\n",
    "    y_str = str(y)\n",
    "    return x_str.strip(), y_str.strip()\n",
    "\n",
    "\n",
    "def _format_sample(x_str, y_str, n_terms, n_digits, int_encoder=None, reverse=False):\n",
    "    # Format a sample of the form \"number_1+number_2+...+number_{n_terms}=answer\".\n",
    "    # Each number_i has n_digits digits\n",
    "    # If a dictionary is passed for int_encoder then use the it to convert characters to integers (so for instance\n",
    "    # convert '3' to 3 or '+' to 12)\n",
    "\n",
    "    if reverse:\n",
    "        x_str = x_str[::-1]\n",
    "\n",
    "    # Prepend an end-of-sequence character \\n and for the target append a start-of-sequence character \\t\n",
    "    x_str = x_str + '\\n'\n",
    "    y_str = '\\t' + y_str + '\\n'\n",
    "    \n",
    "    # Pad x so that is always has the same length.\n",
    "    max_input_digits = input_seq_length(n_terms, n_digits)\n",
    "    x_str = x_str.ljust(max_input_digits)\n",
    "    max_target_digits = target_seq_length(n_terms, n_digits)\n",
    "    y_str = y_str.ljust(max_target_digits)\n",
    "\n",
    "    if int_encoder is not None:\n",
    "        assert isinstance(int_encoder, dict), 'int_encoder must be a dictionary mapping characters to integers'\n",
    "        x_list = [int_encoder[c] for c in x_str]\n",
    "        y_list = [int_encoder[c] for c in y_str]\n",
    "\n",
    "    return x_list, y_list\n",
    "\n",
    "\n",
    "def _generate_samples(n_samples, n_terms=2, n_digits=2, int_encoder=None, one_hot=False, reverse=False, allow_less_terms=False):\n",
    "    # Generate n_samples examples of addition problems as defined in _generate_sample above\n",
    "    X = []\n",
    "    y = []\n",
    "    for _ in range(n_samples):\n",
    "        x_str, y_str = _generate_sample(n_terms, n_digits, allow_less_terms=allow_less_terms)\n",
    "        x_sample, y_sample = _format_sample(x_str, y_str, n_terms, n_digits, int_encoder, reverse)\n",
    "        X.append(x_sample)\n",
    "        y.append(y_sample)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    if one_hot:\n",
    "        X = one_hot_matrix(X, len(int_encoder))\n",
    "        y = one_hot_matrix(y, len(int_encoder))\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def _generate_uniform_samples(n_samples, n_terms=2, n_digits=2, int_encoder=None, one_hot=False, reverse=False):\n",
    "    # Generate samples uniformly w.r.t. the sum\n",
    "    max_sum = (10**n_digits - 1) * n_terms\n",
    "    possible_sums = range(max_sum + 1)\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    for _ in range(n_samples):\n",
    "        x_str, y_str = _generate_sample_from_y(n_terms, n_digits, np.random.choice(possible_sums))\n",
    "        x_sample, y_sample = _format_sample(x_str, y_str, n_terms, n_digits, int_encoder, reverse)\n",
    "        assert len(x_sample) == 6, f'x_str = {x_str}, x_sample = {x_sample}'\n",
    "        X.append(x_sample)\n",
    "        y.append(y_sample)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    if one_hot:\n",
    "        X = one_hot_matrix(X, len(int_encoder))\n",
    "        y = one_hot_matrix(y, len(int_encoder))\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(n_samples, n_terms=2, n_digits=2, int_encoder=None, one_hot=False, reverse=False,\n",
    "                     allow_less_terms=False, uniform=False):\n",
    "    # Generate n_samples series with conditions n_terms and n_digits\n",
    "    if uniform:\n",
    "        X, y = _generate_uniform_samples(n_samples, n_terms, n_digits, int_encoder, one_hot, reverse)\n",
    "    else:\n",
    "        X, y = _generate_samples(n_samples, n_terms, n_digits, int_encoder, one_hot, reverse, allow_less_terms)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "def generate_all_samples(n_terms=2, n_digits=2, int_encoder=None, one_hot=False, reverse=False):\n",
    "    # Generate ALL possible integer addition problems with conditions n_terms and n_digits\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    x_all = range(10 ** n_digits)\n",
    "    x_cartesian = list(product(x_all, repeat=n_terms))\n",
    "    for x in x_cartesian:\n",
    "        x_str = '+'.join([str(a) for a in x])\n",
    "        y_str = str(sum(x))\n",
    "        x_str = x_str.strip()\n",
    "        y_str = y_str.strip()\n",
    "        x_sample, y_sample = _format_sample(x_str, y_str, n_terms, n_digits, int_encoder, reverse)\n",
    "        X.append(x_sample)\n",
    "        y.append(y_sample)\n",
    "\n",
    "    assert len(X) == 10 ** (n_digits * n_terms), \"You didn't generate all possible problems...\"\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    if one_hot:\n",
    "        X = one_hot_matrix(X, len(int_encoder))\n",
    "        y = one_hot_matrix(y, len(int_encoder))\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(X, dataset, one_hot=False):\n",
    "    assert dataset.lower() in ['train', 'test', 'validation'], 'Dataset must be one of \"train\", \"test\", \"validation\"'\n",
    "    # Note that y is not needed, since we can infer the sum from X\n",
    "    \n",
    "    # Split into columns for each term\n",
    "    string_col = decode_matrix(X, int_to_char, one_hot=one_hot)\n",
    "    df = pd.DataFrame({'string': string_col})\n",
    "    summands_df = df['string'].str.split('+', expand=True)\n",
    "    summands_df.columns = [f'term_{i}' for i in range(summands_df.shape[1])]\n",
    "    summands_df[summands_df.columns[-1]] = summands_df[summands_df.columns[-1]].str.replace('\\n', '')\n",
    "    df = df.join(summands_df)\n",
    "    \n",
    "    # Clean up the columns\n",
    "    cols = list(df.columns)\n",
    "    cols.remove('string')\n",
    "    for c in cols:\n",
    "        df[c] = df[c].str.strip('\\n')\n",
    "        df[c] = df[c].str.strip()\n",
    "        df[c] = df[c].astype(int)\n",
    "        \n",
    "    df['sum'] = sum([df[c] for c in cols])\n",
    "    \n",
    "    if dataset.lower() == 'train':\n",
    "        df['set'] = 'Train'\n",
    "    elif dataset.lower() == 'test':\n",
    "        df['set'] = 'Test'\n",
    "    elif dataset.lower() == 'validation':\n",
    "        df['set'] = 'Validation'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_full_df(X_train, X_test, path, fname):\n",
    "    df_train = create_df(X_train, dataset='train')\n",
    "    df_test = create_df(X_test, dataset='test')\n",
    "    df = pd.concat([df_train, df_test])\n",
    "    if not isinstance(path, Path):\n",
    "        path = Path(path)\n",
    "    if not isinstance(fname, Path):\n",
    "        fname = Path(fname)\n",
    "    df.to_csv(path / fname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_from_idx(X, y, train_idx, test_idx=None, save=True, path=None, return_arrays=False):\n",
    "    if test_idx is None:\n",
    "        test_idx = list(set(range(X.shape[0])) - set(train_idx))\n",
    "    \n",
    "    X_train = X[train_idx]\n",
    "    y_train = y[train_idx]\n",
    "    \n",
    "    X_test = X[test_idx]\n",
    "    y_test = y[test_idx]\n",
    "    \n",
    "    if save and (path is not None):\n",
    "        np.save(path / Path('X_train.npy'), X_train)\n",
    "        np.save(path / Path('X_test.npy'), X_test)\n",
    "        np.save(path / Path('y_train.npy'), y_train)\n",
    "        np.save(path / Path('y_test.npy'), y_test)\n",
    "    \n",
    "    if return_arrays:\n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 terms, 2 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_terms = 3\n",
    "n_digits = 2\n",
    "\n",
    "model_dir = Path(f'{n_terms}term_{n_digits}digs')\n",
    "\n",
    "random_dir = random_dir / model_dir\n",
    "uniform_sum_dir = uniform_sum_dir / model_dir\n",
    "sum_strat_dir = sum_strat_dir / model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate_all_samples(n_terms, n_digits, char_to_int_map(), one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 9)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 5)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_df(X, dataset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string</th>\n",
       "      <th>term_0</th>\n",
       "      <th>term_1</th>\n",
       "      <th>term_2</th>\n",
       "      <th>sum</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0+0+0\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0+0+1\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0+0+2\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0+0+3\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0+0+4\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       string  term_0  term_1  term_2  sum    set\n",
       "0  0+0+0\\n          0       0       0    0  Train\n",
       "1  0+0+1\\n          0       0       1    1  Train\n",
       "2  0+0+2\\n          0       0       2    2  Train\n",
       "3  0+0+3\\n          0       0       3    3  Train\n",
       "4  0+0+4\\n          0       0       4    4  Train"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split randomly\n",
    "\n",
    "Randomly split the data into training and testing (70% train, 30% test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2_2_train, X_2_2_test, y_2_2_train, y_2_2_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(random_dir / Path('X_train.npy'), X_2_2_train)\n",
    "np.save(random_dir / Path('X_test.npy'), X_2_2_test)\n",
    "np.save(random_dir / Path('y_train.npy'), y_2_2_train)\n",
    "np.save(random_dir / Path('y_test.npy'), y_2_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_full_df(X_2_2_train, X_2_2_test, random_dir, 'df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratify by sum\n",
    "\n",
    "Stratify the data by the sum, so that a fixed percentage of series summing to each value is kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.sample(frac=0.7, weights='sum', random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string</th>\n",
       "      <th>term_0</th>\n",
       "      <th>term_1</th>\n",
       "      <th>term_2</th>\n",
       "      <th>sum</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501666</th>\n",
       "      <td>50+16+66\\n</td>\n",
       "      <td>50</td>\n",
       "      <td>16</td>\n",
       "      <td>66</td>\n",
       "      <td>132</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778720</th>\n",
       "      <td>77+87+20\\n</td>\n",
       "      <td>77</td>\n",
       "      <td>87</td>\n",
       "      <td>20</td>\n",
       "      <td>184</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0+3+58\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>61</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382484</th>\n",
       "      <td>38+24+84\\n</td>\n",
       "      <td>38</td>\n",
       "      <td>24</td>\n",
       "      <td>84</td>\n",
       "      <td>146</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201255</th>\n",
       "      <td>20+12+55\\n</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>55</td>\n",
       "      <td>87</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            string  term_0  term_1  term_2  sum    set\n",
       "501666  50+16+66\\n      50      16      66  132  Train\n",
       "778720  77+87+20\\n      77      87      20  184  Train\n",
       "358     0+3+58\\n         0       3      58   61  Train\n",
       "382484  38+24+84\\n      38      24      84  146  Train\n",
       "201255  20+12+55\\n      20      12      55   87  Train"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = np.array(df_sample.index)\n",
    "test_idx = np.array(list(set(df.index) - set(train_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, _, _ = train_test_from_idx(X, y, train_idx, test_idx, path=sum_strat_dir, return_arrays=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_full_df(X_train, X_test, sum_strat_dir, 'df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uniform by sum\n",
    "\n",
    "Sample (with replacement) so that each sum appears an equal number of times. From there, randomly sample some data for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7500"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sum'].value_counts().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_over = df.groupby('sum').sample(100, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_full_df(X_train, X_test, uniform_sum_dir, 'df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(uniform_sum_dir / Path('X_train.npy'), X_train)\n",
    "np.save(uniform_sum_dir / Path('X_test.npy'), X_test)\n",
    "np.save(uniform_sum_dir / Path('y_train.npy'), y_train)\n",
    "np.save(uniform_sum_dir / Path('y_test.npy'), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
